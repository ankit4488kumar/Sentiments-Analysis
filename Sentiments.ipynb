{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train & Predict.ipynb","provenance":[],"collapsed_sections":["2FNS6Y4yn1HL","h8AvfgaNqe6t"],"toc_visible":true,"authorship_tag":"ABX9TyM/U/vc9E+TiunBskCRR0Wl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lta6qjlxrbL0"},"source":["## Downloading Dependencies"]},{"cell_type":"code","metadata":{"id":"xGoq-bRvm72j"},"source":[" ! pip install -q kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOLwPCvmpobC","executionInfo":{"status":"ok","timestamp":1602767438843,"user_tz":-330,"elapsed":11425,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"222d8f5a-3662-447b-e370-e04a93833e47","colab":{"base_uri":"https://localhost:8080/","height":649}},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 16.9MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 23.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 42.4MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b08d3b4b30dbacb80e41df98a630f3ec50e524034c0de88a9838e985990e6a6a\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hE5EE1QXlyn0"},"source":["from google.colab import files\n","files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxzVJA7im_5Q","executionInfo":{"status":"ok","timestamp":1602603531649,"user_tz":-330,"elapsed":1142,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"7bea2fc7-ec7a-4a89-ffe9-7dae905b26fe","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["! mkdir ~/.kaggle "],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBYaqzM3nW_q"},"source":["! cp kaggle.json ~/.kaggle/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sxpjg1cdnXFd"},"source":["! chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3zwBxvhariqY"},"source":["## Connecting with Drive"]},{"cell_type":"code","metadata":{"id":"r3G3hcGgmmXa","executionInfo":{"status":"ok","timestamp":1602767490248,"user_tz":-330,"elapsed":39369,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"e7fb8f22-56e7-4b29-832a-c00978be251f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dfiZhqlNyEWK","executionInfo":{"status":"ok","timestamp":1602767490253,"user_tz":-330,"elapsed":38771,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"138cdea5-744e-4deb-b604-ab54c49a552f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive \n","!ls /mydrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/mydrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZeAG_BgQtvHw","executionInfo":{"status":"ok","timestamp":1602767490255,"user_tz":-330,"elapsed":38149,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"c52e10c3-53d0-4469-ed20-e3e1969ae68e","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EMA5IAVzmWrI","executionInfo":{"status":"ok","timestamp":1602767490256,"user_tz":-330,"elapsed":37557,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"38b125c1-e52a-4a4d-92fa-a7bb39835e6e","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"2FNS6Y4yn1HL"},"source":["## Path for data download"]},{"cell_type":"code","metadata":{"id":"vm6YQNxjnNSq","executionInfo":{"status":"ok","timestamp":1602605299934,"user_tz":-330,"elapsed":1757,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"0aeee1b5-ba98-497a-fa37-d34f3fdabb00","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/sentiment analysis/input"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/sentiment analysis/input\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2CP-zThJn37A","executionInfo":{"status":"ok","timestamp":1602603784185,"user_tz":-330,"elapsed":8515,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"7b712aaa-f8e9-4d7e-e41a-787fb5d4c26d","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["!kaggle datasets download -d abhishek/bert-base-uncased"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading bert-base-uncased.zip to /content/content/My Drive/sentiment analysis/input\n"," 97% 378M/389M [00:06<00:00, 54.1MB/s]\n","100% 389M/389M [00:06<00:00, 63.9MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KXm3xFQjoDtH","executionInfo":{"status":"ok","timestamp":1602605302809,"user_tz":-330,"elapsed":1740,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"c0fab6b8-6acc-4fca-b287-3162207ea155","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/sentiment analysis/input'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"ZiCvTQyVtbuf","executionInfo":{"status":"ok","timestamp":1602605303623,"user_tz":-330,"elapsed":1724,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"1bffc29a-7b10-450c-87ea-6ced7e22bc65","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" bert_base_unchased  'IMDB Dataset.csv'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8cxwJBjLn9If","executionInfo":{"status":"ok","timestamp":1602603860869,"user_tz":-330,"elapsed":8395,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"d084ec9d-4321-4704-d797-8e865bbd2cd7","colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["! unzip bert-base-uncased.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  bert-base-uncased.zip\n","  inflating: config.json             \n","  inflating: pytorch_model.bin       \n","  inflating: vocab.txt               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HLXAz4Slouez"},"source":["!rm -r bert-base-uncased.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wg9ShU_JoiJC"},"source":["!mv config.json pytorch_model.bin vocab.txt bert_base_unchased/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h8AvfgaNqe6t"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"6mYgEjpDpUGS"},"source":["Change path to working directory\n"]},{"cell_type":"code","metadata":{"id":"EfH_mDuVpH0T","executionInfo":{"status":"ok","timestamp":1602605314681,"user_tz":-330,"elapsed":1770,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"ea5214c8-efca-4fae-d610-26878b4905d4","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/sentiment analysis/src"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/sentiment analysis/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8YD1Q6LfrpVl"},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdGdSSgopgSx","outputId":"f39126bc-177f-4e1c-d9dd-afe3f18f2921","colab":{"base_uri":"https://localhost:8080/","height":951}},"source":["!python train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-13 16:08:43.867970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 5625/5625 [45:05<00:00,  2.08it/s]\n","  0% 0/1250 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 1250/1250 [01:43<00:00, 12.03it/s]\n","Accuracy Score = 0.9174\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 5625/5625 [45:21<00:00,  2.07it/s]\n","  0% 0/1250 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 1250/1250 [01:44<00:00, 12.00it/s]\n","Accuracy Score = 0.9238\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 5625/5625 [45:20<00:00,  2.07it/s]\n","  0% 0/1250 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100% 1250/1250 [01:43<00:00, 12.02it/s]\n","Accuracy Score = 0.923\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","  1% 70/5625 [00:33<44:46,  2.07it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bBXn_Ikjph3w"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-nZMi6lysGgX"},"source":["## Prediction"]},{"cell_type":"code","metadata":{"id":"QmgYN36MyJSX","executionInfo":{"status":"ok","timestamp":1602767519923,"user_tz":-330,"elapsed":1747,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"20ff9225-8ad9-4d4c-954f-dae9526bb0c9","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd /content/drive/My Drive/sentiment analysis/src"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/sentiment analysis/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"95_RnkGTsHwk"},"source":["import config\n","import torch\n","import time\n","from model import BERTBaseUncased\n","import functools\n","import torch.nn as nn\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDLUZOKhsTzA"},"source":["MODEL = None\n","DEVICE = config.DEVICE\n","PREDICTION_DICT = dict()\n","\n","\n","def sentence_prediction(sentence):\n","    tokenizer = config.TOKENIZER\n","    max_len = config.MAX_LEN\n","    review = str(sentence)\n","    review = \" \".join(review.split())\n","\n","    inputs = tokenizer.encode_plus(\n","        review, None, add_special_tokens=True, max_length=max_len\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    padding_length = max_len - len(ids)\n","    ids = ids + ([0] * padding_length)\n","    mask = mask + ([0] * padding_length)\n","    token_type_ids = token_type_ids + ([0] * padding_length)\n","\n","    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n","    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n","    token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n","\n","    ids = ids.to(DEVICE, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n","    mask = mask.to(DEVICE, dtype=torch.long)\n","\n","    outputs = MODEL(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","\n","    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n","    return outputs[0][0]\n","\n","\n","def predict(sentence):\n","    sentence = sentence\n","    start_time = time.time()\n","    positive_prediction = sentence_prediction(sentence)\n","    negative_prediction = 1 - positive_prediction\n","    response = {}\n","    response[\"response\"] = {\n","        \"time\": str(datetime.datetime.now())[:-7],\n","        \"positive\": str(positive_prediction),\n","        \"negative\": str(negative_prediction),\n","        \"sentence\": str(sentence),\n","        \"time_taken\": str(time.time() - start_time),\n","    }\n","    return response\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c6joKfdsT5H","executionInfo":{"status":"ok","timestamp":1602761447341,"user_tz":-330,"elapsed":5016,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"ed771fd4-440c-4510-c96e-75c5e8415fc0","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["MODEL = BERTBaseUncased()\n","MODEL.load_state_dict(torch.load(config.MODEL_PATH))\n","MODEL.to(DEVICE)\n","MODEL.eval()\n","\n","## Enter Prediction text in predict \n","response = predict(\"Simple Online and Realtime Tracking (SORT) is a pragmatic approach to multiple object tracking with a focus on simple effective algorithms\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZoE32lmOsT7h","executionInfo":{"status":"ok","timestamp":1602761433373,"user_tz":-330,"elapsed":920,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"2897ce54-86f9-442b-a8e3-353e48a940da","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["response[\"response\"][\"time\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2020-10-15 11:30:30.'"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"dkRiDBfc0IYE","executionInfo":{"status":"ok","timestamp":1602761510585,"user_tz":-330,"elapsed":1111,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"c92c39c7-8a83-441d-c65d-46e70019a67f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["response[\"response\"][\"positive\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.98250556'"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"6t7oN_7-B8nn","executionInfo":{"status":"ok","timestamp":1602761523907,"user_tz":-330,"elapsed":1148,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"47aaafd3-ae8e-402f-ee24-3f2bbcfae49c","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["response[\"response\"][\"negative\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.01749444007873535'"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"vviytS_xB_26","executionInfo":{"status":"ok","timestamp":1602761533116,"user_tz":-330,"elapsed":1531,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"40a85471-5c36-4c48-a143-982256f5db07","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["response[\"response\"][\"sentence\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Simple Online and Realtime Tracking (SORT) is a pragmatic approach to multiple object tracking with a focus on simple effective algorithms'"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"YJ2snhXhCCBf","executionInfo":{"status":"ok","timestamp":1602761541927,"user_tz":-330,"elapsed":1444,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"748ccd4e-e49b-486d-aff2-67b656ca9ae1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["response[\"response\"][\"time_taken\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.03959536552429199'"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"yW4hpRBOCEMs","executionInfo":{"status":"ok","timestamp":1602761556683,"user_tz":-330,"elapsed":1174,"user":{"displayName":"bharat choudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1_coNe7xN16FZobNEROxOJ1BS7-zlNtG5cgAP5Q=s64","userId":"00345134375347289406"}},"outputId":"b4a55d6d-5a77-46ff-be02-800a72c16ccd","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["response['response']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'negative': '0.01749444007873535',\n"," 'positive': '0.98250556',\n"," 'sentence': 'Simple Online and Realtime Tracking (SORT) is a pragmatic approach to multiple object tracking with a focus on simple effective algorithms',\n"," 'time': '2020-10-15 11:30:46',\n"," 'time_taken': '0.03959536552429199'}"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"bBoq2x4UeAm-"},"source":[""],"execution_count":null,"outputs":[]}]}